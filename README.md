# DIP_Ys
我的数字图像处理实验课设，基于传统图像处理的车牌区域识别。项目时间2024.12。

## 说明
只传了结课大作业，内容是车牌区域的识别。测试集的识别难度强如怪物（详见input_images文件夹），拼尽全力无法战胜。
达到这样的准确度应该是传统图像处理手段的极限了吧？要是能用神经网络就好了。

在不同的环境里跑出来的结果也许有不同，调参就好。最高能达到80%的准确度。

我的结果大概长这样：

![15](https://github.com/user-attachments/assets/3620d7f7-13d5-45b6-a163-92c48d24c1a1)
![2](https://github.com/user-attachments/assets/54fa46bc-7028-451d-be27-378d6076bfb6)
![5](https://github.com/user-attachments/assets/a5705a98-6d20-4cf4-8f72-3b0bfd6e3aa0)


## 结课论文部分内容：
在本次项目中，我我运用了数字图像处理课程的相关理论，采用Pycharm IDE环境，使用Python语言结合OpenCV库编程，按照要求对包含20张照片的数据集进行了车牌的图像分割处理。将最终分割结果复制到对应图像的左下角，并在每幅图像的右下角生成本人姓名和学号信息。

通过本次实验我发现，传统的cv方法（基础的数字图像处理）对于严重欠曝过曝，偏色严重等情况时，处理能力十分有限，误识别概率高（即使是在使用了直方图均衡化等图像增强方式后，由于图像所含信息过少，仍然会出现误识别漏识别的情况，甚至会影响其他正常图像的识别）。

在Python环境下，可以使用一些基于对象检测的方法，如Haar级联分类器、HOG特征与SVM分类器，或者深度学习模型（如YOLO、SSD等）来对于训练与检测车牌区域，识别效率将会大大提高。由于本次项目是基于数字图像处理课程，所以我只使用了传统的图像处理方法。



